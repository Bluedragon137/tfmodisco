{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kundajelab/tfmodisco/blob/master/examples/simulated_TAL_GATA_deeplearning/TF_MoDISco_TAL_GATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPV0Wsfg9OBZ"
   },
   "source": [
    "# TF-MoDISco on the TAL GATA simulation\n",
    "\n",
    "### Note: we are still refining the multi-task version of TF-MoDISco. If you encounter difficulties running TF-MoDISco with multiple tasks, our recommendation is to run it on one task at a time.\n",
    "\n",
    "This notebook demonstrates running TF-MoDISco on importance scores obtained from the TAL-GATA simulation used in the DeepLIFT paper. See Generate Importance Scores.ipynb for a notebook demonstrating how to produce the scores. There are 3 tasks. Task 0 is positive when both TAL and GATA motifs are present in the sequence. Task 1 is positive when GATA motifs are present in the sequence. Task 2 is positive when TAL motifs are present in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "CLiK1j6A8YrA",
    "outputId": "59297c1a-69dc-49e8-b2e2-1434e0377ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modisco in /Users/avantishrikumar/Research/modisco (0.5.6.0)\n",
      "Requirement already satisfied: numpy>=1.9 in /Users/avantishrikumar/anaconda3/lib/python3.7/site-packages (from modisco) (1.16.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/avantishrikumar/anaconda3/lib/python3.7/site-packages (from modisco) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in /Users/avantishrikumar/anaconda3/lib/python3.7/site-packages (from modisco) (0.20.3)\n",
      "Requirement already satisfied: h5py>=2.5 in /Users/avantishrikumar/anaconda3/lib/python3.7/site-packages (from modisco) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/avantishrikumar/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.19->modisco) (1.2.1)\n",
      "Requirement already satisfied: six in /Users/avantishrikumar/anaconda3/lib/python3.7/site-packages (from h5py>=2.5->modisco) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install modisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "en15RxNL8YFE"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    reload  # Python 2.7\n",
    "except NameError:\n",
    "    try:\n",
    "        from importlib import reload  # Python 3.4+\n",
    "    except ImportError:\n",
    "        from imp import reload  # Python 3.0 - 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "id": "uVOSJpXV8aIG",
    "outputId": "c6b30071-9329-4463-b6c0-88c6009691d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import modisco\n",
    "import sys\n",
    "print (sys.version)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROG0LVF_9ZZs"
   },
   "source": [
    "## Grab the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "bZ8jaBDZ8fmm",
    "outputId": "d8b7fb89-f81a-414a-bd02-85095a9326ba"
   },
   "outputs": [],
   "source": [
    "#grab scores for tfmodisco\n",
    "#!/usr/bin/env bash\n",
    "![[ -f scores.h5 ]] || curl -o scores.h5 https://raw.githubusercontent.com/AvantiShri/model_storage/23d8f3ffc89af210f6f0bf7e65585eff259ba672/modisco/scores.h5\n",
    "![[ -f sequences.simdata.gz ]] || wget https://raw.githubusercontent.com/AvantiShri/model_storage/db919b12f750e5844402153233249bb3d24e9e9a/deeplift/genomics/sequences.simdata.gz\n",
    "![[ -f test.txt.gz ]] || wget https://raw.githubusercontent.com/AvantiShri/model_storage/9aadb769735c60eb90f7d3d896632ac749a1bdd2/deeplift/genomics/test.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ShCbHRM92_y"
   },
   "source": [
    "## Functions for one-hot encoding sequencesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KawKTu5P8-c6"
   },
   "outputs": [],
   "source": [
    "#Functions for one-hot encoding sequences\n",
    "import gzip\n",
    "\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "\n",
    "#read in the data in the testing set\n",
    "test_ids_fh = gzip.open(\"test.txt.gz\",\"rb\")\n",
    "ids_to_load = set([x.rstrip() for x in test_ids_fh])\n",
    "\n",
    "fasta_sequences = []\n",
    "for i,a_line in enumerate(gzip.open(\"sequences.simdata.gz\",\"rb\")):\n",
    "    if (i==0):\n",
    "        next\n",
    "    a_line = a_line.rstrip()\n",
    "    seq_id,seq_fasta,embeddings,task1,task2,task3 = a_line.split(b\"\\t\")\n",
    "    if seq_id in ids_to_load:\n",
    "        fasta_sequences.append(seq_fasta.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1xkAlvW97vL"
   },
   "source": [
    "## Prepare the data for input into TF-MoDISCo\n",
    "\n",
    "You need a numpy array of importance scores and hypothetical importance scores for every task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xahZGqrA9Jpq"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from collections import OrderedDict\n",
    "\n",
    "task_to_scores = OrderedDict()\n",
    "task_to_hyp_scores = OrderedDict()\n",
    "\n",
    "f = h5py.File(\"scores.h5\",\"r\")\n",
    "tasks = f[\"contrib_scores\"].keys()\n",
    "n = 100 #since this is just a test run, for speed I am limiting to 100 sequences\n",
    "for task in tasks:\n",
    "    #Note that the sequences can be of variable lengths;\n",
    "    #in this example they all have the same length (200bp) but that is\n",
    "    #not necessary.\n",
    "    task_to_scores[task] = [np.array(x) for x in f['contrib_scores'][task][:n]]\n",
    "    task_to_hyp_scores[task] = [np.array(x) for x in f['hyp_contrib_scores'][task][:n]]\n",
    "\n",
    "onehot_data = [one_hot_encode_along_channel_axis(seq) for seq in fasta_sequences][:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQEQgz1w-QhL"
   },
   "source": [
    "Double check by plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "Ky6nlCFs-NcP",
    "outputId": "f62e9326-372a-464c-bfe2-5333777cc534"
   },
   "outputs": [],
   "source": [
    "import modisco.visualization\n",
    "from modisco.visualization import viz_sequence\n",
    "\n",
    "viz_sequence.plot_weights(task_to_scores['task0'][0], subticks_frequency=20)\n",
    "viz_sequence.plot_weights(task_to_hyp_scores['task0'][0], subticks_frequency=20)\n",
    "viz_sequence.plot_weights(onehot_data[0], subticks_frequency=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uuvSgm62-Whl"
   },
   "source": [
    "Run TF-MoDISco\n",
    "TF-MoDISco first identifies seqlets, then splits the seqlets into \"metaclusters\" according to their pattern of activity across all the tasks, and then performs clustering within each task. Since there are 3 tasks, there are 27 possible metaclusters (consisting of a +1, -1 or 0 for each task). Consistent with the simulation, the [+1, +1, 0], [+1, 0, +1], [0, 0, +1] and [0, +1, 0] metaclusters turn up motifs.\n",
    "\n",
    "To demonstrate customization, the code below has slight modifications from default settings in the following ways:\n",
    "\n",
    "- Because the TAL and GATA motifs are relatively short compared to something like CTCF, it uses a sliding window size of 15 (rather than the default of 21) and flanks of 5 (rather than the default of 10). The sliding window size and flanks should be adjusted according to the expected length of the core motif and its flanks. If the window size or flank sizes are too long, you risk picking up more noise.\n",
    "- During the seqlet clustering, motifs are trimmed to the central trim_to_window_size bp with the highest importance. trim_to_window_size is set to 10 rather than the default of 30. After the trimming is done, the seqlet is expanded on either side by initial_flank_to_add. This is set to 3 rather than the default of 10.\n",
    "- The final_min_cluster_size is set to 60 rather than the default of 30. This is used to filter out small clusters with relatively weak support (in this case, fewer than 60 seqlets).\n",
    "- It uses kmers of length 5 with 1 gap and no mismatches to compute the \"quick and dirty\" affinity matrix across all seqlets. The \"quick and dirty\" affinity matrix is used both for noise filtering and as a first pass to speed up computation of the continuous jaccard affinity matrix (the latter affinities are only computed between seqlets deemed to be close together by the \"quick and dirty\" method). I made the kmer length smaller to keep memory usage down when testing on my macbook pro. The default is to use kmers of length 8 with 3 gaps and 2 mismatches, which tends to run out of memory on many systems (I would change the default but want to avoid breaking reproducibility for older users)\n",
    "- target_seqlet_fdr controls the noisiness of the seqlets. For a particular task, \"significant\" seqlets are identified by first smoothing importance scores with a window of size sliding_window_size and then fitting a laplace distribution to the left and right tails. This laplace distribution is assumed to represent the null distribution of window importance scores (note: as an alternative, it's possible to supply an empirical null distribution; see examples/H1ESC_Nanog_gkmsvm/TF MoDISco Nanog.ipynb for an example). A threshold is then identified such that the false discovery rate (computed as the ratio of the expected fraction of windows with a certain score in the null distribution relative to the observed fraction of windows with that score) is less that target_seqlet_fdr. Note: if the number of sliding windows that pass the FDR threshold is smaller than min_passing_windows_frac (default value 0.03 at the time of writing) or larger than max_passing_windows_frac (default value of 0.2 at the time of writing), the threshold will be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "--8gp-i2-TOm",
    "outputId": "93401d0a-1d7b-44f9-af8a-e851acdf10c4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY 0.33265664\n",
      "On task task0\n",
      "Computing windowed sums on original\n",
      "Generating null dist\n",
      "peak(mu)= -0.02237087196292123\n",
      "Computing threshold\n",
      "Thresholds from null dist were -1.0124836564064026  and  0.8997364044189453\n",
      "Final raw thresholds are -1.0124836564064026  and  0.8997364044189453\n",
      "Final transformed thresholds are -0.8494086021505376  and  0.8402150537634409\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 198 coords\n",
      "On task task1\n",
      "Computing windowed sums on original\n",
      "Generating null dist\n",
      "peak(mu)= -0.00025505211204290357\n",
      "Computing threshold\n",
      "Thresholds from null dist were -0.918197512626648  and  0.608733057975769\n",
      "Final raw thresholds are -0.918197512626648  and  0.608733057975769\n",
      "Final transformed thresholds are -0.9040322580645161  and  0.8833870967741936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 145 coords\n",
      "On task task2\n",
      "Computing windowed sums on original\n",
      "Generating null dist\n",
      "peak(mu)= -0.001713569819345139\n",
      "Computing threshold\n",
      "Thresholds from null dist were -0.6213091909885406  and  0.6281718015670776\n",
      "Final raw thresholds are -0.6213091909885406  and  0.6281718015670776\n",
      "Final transformed thresholds are -0.8680107526881721  and  0.8682795698924731\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXSUlEQVR4nO3de4xc53nf8e+zM8uLqFhXSlEpxZRTVo5sVLJByEoFBHLd6NbAcgMbkdDahOuCaSA3dhGglVugKhIkUtDGat06KpRYtZw4tgVfKjZRbDOqALeALYuyBVk3i6wvEkVKpEppKYncXc7M0z/mDDm73MtcDnfOeL8fYHFm3j0z8+yC/M27z3nPmchMJEmrw8SoC5AkrRxDX5JWEUNfklYRQ1+SVhFDX5JWkfqoC1jKueeem5s3bx51GZI0Vh599NGXM3PjQt+rdOhv3ryZXbt2jboMSRorEfHTxb5ne0eSVhFDX5JWEUNfklYRQ1+SVhFDX5JWEUNfklYRQ1+SVhFDX5JWEUNfklaRSp+RO1Yeuv3E7Xd/YnR1SNISnOlL0ipi6EvSKmLoS9IqYuhL0ipi6EvSKmLoz/fxj7e/+nRkKrnzN2bZv7u1Yq8pSf0y9Od77LH2V5/+9/df5fBB+Pau11bsNSWpX4Z+SbLR3rYao61DkpZi6Jek1QgAshkjrkSSFmfol6TVnLuVpCoy9EvSaeukoS+pwgz9kmTR3rGnL6nKDP2SdNo69vQlVZmhXxJX70gaB4Z+SezpSxoHhn5JWkVbp2V7R1KFGfolSWf6ksaAoV+Slj19SWPA0C9Jp63jTF9SlRn6JTmxeseevqTqMvRL4uodSePA0C9JZ4bvtXckVZmhXxJX70gaB4Z+SY5fZdOevqQKM/RLcuJ6+iMuRJKWYOiXxGvvSBoHhn5JvMqmpHGwbOhHxEUR8VBEPB0RT0bEx4rxsyNiZ0TsLrZnFeMREZ+KiD0R8XhEvLPrubYV+++OiG2n7sdaeZ6RK2kc9DLTbwC/k5m/BFwJ3BIRlwK3Ag9m5hbgweI+wPXAluJrO3AXtN8kgNuAdwFXALd13ih+FqQ9fUljYNnQz8z9mfm94vZrwNPAJuBG4N5it3uB9xW3bwQ+l23fAc6MiAuAa4GdmXkoM18BdgLXlfrTjJCfkStpHPTV04+IzcA7gIeB8zNzP7TfGIDzit02Ac93PWxvMbbY+M+EE2fk2tOXVF09h35EnA58Bfh4Zh5eatcFxnKJ8fmvsz0idkXEroMHD/Za3sh1wt6evqQq6yn0I2KSduB/PjO/Wgy/VLRtKLYHivG9wEVdD78Q2LfE+ByZeXdmbs3MrRs3buznZxkpr70jaRz0snongM8AT2fmJ7u+tQPorMDZBtzfNf6hYhXPlcBU0f75BnBNRJxVHMC9phj7mdDyKpuSxkC9h32uAj4I/CAiHivG/g1wB3BfRHwEeA74QPG9B4AbgD3AEeDDAJl5KCJ+D3ik2O93M/NQKT9FBaTX05c0BpYN/cz8Pyzcjwd4zwL7J3DLIs91D3BPPwWOi9axYmvoS6owz8gtyYkzcqH9vidJ1WPol6RzchYZZNPQl1RNhn5JupdqNo/Z45FUTYZ+SVpNiHp7ht+cNfQlVZOhX4LMJBtBbU37futYa7QFSdIiDP0StBrtkK+vc6YvqdoM/RJ0Qr62tgh9e/qSKsrQL8GJ0J97X5KqxtAvwfyZvj19SVVl6JfAmb6kcWHol6AT8nV7+pIqztAvwUkHcp3pS6ooQ78EzZm57R17+pKqytAvgTN9SePC0C/BSQdy7elLqihDvwTO9CWNC0O/BPNn+vb0JVWVoV+Ck5ZsOtOXVFGGfgm89o6kcWHol8AzciWNC0O/BMdDf53X3pFUbYZ+CU709Ofel6SqMfRL4JJNSePC0C+BB3IljQtDvwSd0J9YA0Q605dUWYZ+CRozDQAmau0vD+RKqipDvwTN2SYxkcQERM2evqTqMvRL0JxtEvX27Ym6PX1J1WXol6A522Si1r4dNXv6kqrL0C9Be6bfXrkzUbenL6m6DP0SNGebTBTtHXv6kqrM0C9Ba7Z1vL0zUUtn+pIqy9AvQXum327vONOXVGWGfglcvSNpXBj6JbCnL2lcLBv6EXFPRByIiCe6xv59RLwQEY8VXzd0fe8TEbEnIn4YEdd2jV9XjO2JiFvL/1FGp3vJ5kTdnr6k6uplpv9Z4LoFxu/MzMuLrwcAIuJS4CbgbcVj/jgiahFRAz4NXA9cCtxc7PszoXvJpjN9SVVWX26HzPxWRGzu8fluBL6YmTPAjyNiD3BF8b09mfkjgIj4YrHvU31XXEHd7Z2Jmj19SdU1TE//oxHxeNH+OasY2wQ837XP3mJssfGTRMT2iNgVEbsOHjw4RHkrpzHTIDpn5NY9I1dSdQ0a+ncBvwhcDuwH/qgYjwX2zSXGTx7MvDszt2bm1o0bNw5Y3srqXrLpVTYlVdmy7Z2FZOZLndsR8SfAXxZ39wIXde16IbCvuL3Y+NhrzjZZs6F9256+pCobaKYfERd03f1HQGdlzw7gpohYGxEXA1uA7wKPAFsi4uKIWEP7YO+OwcuuluZs83h7x3X6kqps2Zl+RHwBuBo4NyL2ArcBV0fE5bRbND8BfhMgM5+MiPtoH6BtALdkZrN4no8C3wBqwD2Z+WTpP82IzD0j156+pOrqZfXOzQsMf2aJ/X8f+P0Fxh8AHuirujExZ/WOV9mUVGGekVuC7vaOPX1JVWbol2D+6h17+pKqytAfUmbOu/aOPX1J1WXoDymbCcmcnn42k2wteBqCJI2UoT+kzqy+u6cPtngkVZOhP6RO6B/v6RdbV/BIqiJDf0jHZ/pd19PvHpekKjH0h9SYaQB0fUZue2t7R1IVGfpDmt/ecaYvqcoM/SHNb+/Y05dUZYb+kI7P9Oev3nGmL6mCDP0hnbx6pxi3py+pggz9IZ28eifnjEtSlRj6Q5rf3unM9O3pS6oiQ39Ix0N/0tU7kqrP0B/SSTN91+lLqjBDf0j29CWNE0N/SIut3rGnL6mKDP0hLXqVTWf6kirI0B/SiZk+xbZo79jTl1RBhv6QmjNzQ9+ZvqQqM/SHdKK9c+IzcsGevqRqMvSHNL+940xfUpUZ+kOypy9pnBj6Q2rONomJIIrfpDN9SVVm6A+pOduktqZ2/L7r9CVVmaE/pPmh70xfUpUZ+kNqzjapre0K/YCJ+oQ9fUmVZOgPaf5MH2BicsKZvqRKMvSHtFDo19bU7OlLqiRDf0gLhv5kzZm+pEoy9Ie02Ezfnr6kKjL0h7RYT781a3tHUvUY+kNqzjjTlzQ+DP0h2dOXNE6WDf2IuCciDkTEE11jZ0fEzojYXWzPKsYjIj4VEXsi4vGIeGfXY7YV+++OiG2n5sdZea7ekTROepnpfxa4bt7YrcCDmbkFeLC4D3A9sKX42g7cBe03CeA24F3AFcBtnTeKcec6fUnjZNnQz8xvAYfmDd8I3Fvcvhd4X9f457LtO8CZEXEBcC2wMzMPZeYrwE5OfiMZS67ekTROBu3pn5+Z+wGK7XnF+Cbg+a799hZji42fJCK2R8SuiNh18ODBActbOfb0JY2Tsg/kxgJjucT4yYOZd2fm1szcunHjxlKLOxWas03qa+tzxmprDH1J1TRo6L9UtG0otgeK8b3ARV37XQjsW2J87DVnm0ysmftrnJic8ECupEoaNPR3AJ0VONuA+7vGP1Ss4rkSmCraP98AromIs4oDuNcUY2NvwfbO1B6ar7wID90+oqokaWH15XaIiC8AVwPnRsRe2qtw7gDui4iPAM8BHyh2fwC4AdgDHAE+DJCZhyLi94BHiv1+NzPnHxweSwuGfj1oNpzpS6qeZUM/M29e5FvvWWDfBG5Z5HnuAe7pq7qqe+h2mtOz1F58BN5+YrhWh2ZjdGVJ0mI8I3dIzUY75LtN1KFl6EuqIEN/CK1mki2oTc5dnFSbdKYvqZoM/SE0j7W3J830a4a+pGoy9IfQCfb5oV+bPPGGIElVYugP4fhMf3LueK0GLc/NklRBhv4QlpvptxczSVJ1GPpDWGymP1FvH9hNl+pLqhhDfwiLzvSL+/b1JVWNoT+E5rF2+6Y+f8lmJ/RdwSOpYgz9IXRCfWKxmb6hL6liDP0hfP//HgZg9yuH54x33gQ8K1dS1Rj6Q2hMt7eT6+eu0nGmL6mqDP0hNI62e/k1Q1/SmDD0h9AJ/fr6ueOdJZydA72SVBWG/hAaR9qhP7+9M1Frj3tWrqSqMfSH0JiGiXoyMf8yDMdn+itfkyQtxdAfQuNoUF9/cgunVnyQVtOZvqSKMfSH0A79k8ed6UuqKkN/CI0jC8/0XacvqaoM/SEs2t5xyaakijL0h9CYxtCXNFYM/SEs2tMvLq3cbLhOX1K1GPpDWKy9Y09fUlUZ+gPKVi7a3nn8xVcA+OHeN1a6LElakqE/oNnXZyEXnul3xjoXZJOkqjD0BzQ91U70BXv6a4HI49fmkaSqMPQHNDM1Ayzc3okJqK87cW0eSaoKQ39AJ2b6C6/Qqa9PjjnTl1Qxhv6AZg4vPtPvjDeOrmRFkrQ8Q39AJ9o7C3+/fpo9fUnVY+gPaPn2Doa+pMox9Ae01IHczrihL6lqDP0BTU9NQ2R7eeYC7OlLqiJDf0Azh2eor4dYZDI/Wcz0M73+jqTqMPQHNDM1s2hrB9o9/WwGjaNegEdSdQwV+hHxk4j4QUQ8FhG7irGzI2JnROwutmcV4xERn4qIPRHxeES8s4wfYFSWD/329zoHfCWpCsqY6b87My/PzK3F/VuBBzNzC/BgcR/gemBL8bUduKuE1x6Z6anppUP/tPb3Ogd8JakKTkV750bg3uL2vcD7usY/l23fAc6MiAtOweuviE5PfzHO9CVV0bChn8A3I+LRiNhejJ2fmfsBiu15xfgm4Pmux+4txuaIiO0RsSsidh08eHDI8k6dXnr6nf0kqSrqQz7+qszcFxHnATsj4pkl9l1onctJqZmZdwN3A2zdurWyS1+mp6bZ8Av29CWNl6Fm+pm5r9geAL4GXAG81GnbFNsDxe57gYu6Hn4hsG+Y1x+VzGRmaobJHg7kOtOXVCUDh35EbIiIn+vcBq4BngB2ANuK3bYB9xe3dwAfKlbxXAlMddpA46Yx3aDVaNnTlzR2hmnvnA98LdpnJ9WBv8jMr0fEI8B9EfER4DngA8X+DwA3AHuAI8CHh3jtkerM3mtLzfTXAZHO9CVVysChn5k/Ai5bYPz/Ae9ZYDyBWwZ9vSrpzN6Xau90PkjFmb6kKvGM3AEsd7G1jvp6Z/qSqsXQH8CJD1BZej9DX1LVGPoDWO5a+h319Wl7R1KlGPoD6L2945JNSdVi6A/Amb6kcWXoD2C5z8ftsKcvqWoM/QHMHJ5hcsMkscxvrzPT94NUJFWFoT+A6alp1p2xbtn96qdB61iLxrQfpCKpGgz9AcxMzbD2jEU+HLeL19+RVDWG/gBmpmZ6mulPev0dSRVj6A9g5rAzfUnjydAfwPTUNGvf1Evot7edM3gladQM/QH029O3vSOpKgz9AfS+esf2jqRqMfT71DzWpHG00d9Mf9dfwUO3n+rSJGlZhn6fOv35nnr6xR8DM294cpakajD0+9Rp1fTS3okJWHMaTL9xqquSpN4Y+n2a/ps/BmDtc3/V0/7rNsCMoS+pIgz9Ph19rb1dt6G3/dduCNs7kirD0O/Tww+/DsBP49We9l+3wfaOpOow9Ps09eMa685psfaM3mbva23vSKoQQ79PUz+qccbFzZ73X7chmLa9I6kiDP0+vP7i60wfmuCMt/Qe+mtPd6YvqToM/T7sfXgvAGdc3Or5MWs3wPTrp6oiSeqPod+HF777AlFL3vTm/to7zWPQmLXFI2n0DP0+vPDwC5y+qUVtTe+PWVss7bTFI6kKDP0eZSvZ98i+vvr5cGI9v8s2JVWBod+jl595mZnDM32t3IH2yVng9XckVYOh36POQdwz39L7QVxwpi+pWuqjLmAc3LnzWY5+5SnYMMlp5/cX+mtPb29nXMEjqQIM/R41n3mZ2iXnEBOH+nrc2tPa7Z3DL+fca+q/+xNllidJPbG904OcbtD68RS1t57T92OfPHyIdWe3+PqnG/yPOxpMvWRvX9LoGPo9+Nt/cy+0kred80jfj61Nwi/f9gabr53liYda/JcPHeOJh/o7GCxJZbG9s4g7dz4LQGtqhmN/to71G1uc9dbBwnpyA/yd989y0buP8YM/WcfX/jA599df5Ocv//kyS5akZTnTX0K2kqN/+G1mXwsu++dHqS//CYlLWn9OctlvTTO5IfnSr3+Jo4eOllOoJPVoxUM/Iq6LiB9GxJ6IuHWlX38pd+58ludfOcrzr7TDePZLT9HctZ+3/sYMb3pzf6t2FrP2jOSy3zrKq3sP80fXfo5Pfv2ZUp5Xknqxou2diKgBnwZ+FdgLPBIROzLzqZWso9udO58lW0lOzZAvHyFfnSanGxz5d9+i8d191K/+BS68+slSX/PMt7S49KYjPPVnL9L68F/w08YB4vQ13Hf3d2EioBbE+jq//d63UV9fJyJKfX1Jq9dK9/SvAPZk5o8AIuKLwI3AKQn922+6j9kdu5ff8VgLGu2ZfIspANbWn+P8q5pc8v4nORWZu+lXjkHAS7vq5NNHyJeP8MZv/vWcff6A+6E+AZNz/yBbUztxf7ZZzl8g0qmw2L/Vsv4Ndz9Pt8Wec7H9q+bm/3kzm6/efEqeOzJXbglhRLwfuC4z/1lx/4PAuzLzo137bAe2F3cvAX64YgWW41zg5VEXMYBxrRusfRTGtW4Y39r7qfvNmblxoW+s9Ex/oTnznHedzLwbuHtlyilfROzKzK2jrqNf41o3WPsojGvdML61l1X3Sv+tsxe4qOv+hcC+Fa5BklatlQ79R4AtEXFxRKwBbgJ2rHANkrRqrWh7JzMbEfFR4BtADbgnM8tdGjN649qaGte6wdpHYVzrhvGtvZS6V/RAriRptMZj/ZIkqRSGviStIoZ+Sap8eYmlRMRFEfFQRDwdEU9GxMdGXVM/IqIWEd+PiL8cdS39iIgzI+LLEfFM8bv/5VHX1KuI+JfFv5UnIuILEbFu1DUtJiLuiYgDEfFE19jZEbEzInYX27NGWeNCFqn7PxT/Xh6PiK9FxJmDPLehX4Kuy0tcD1wK3BwRl462qp41gN/JzF8CrgRuGaPaAT4GPD3qIgbwn4GvZ+ZbgcsYk58hIjYBvw1szcy3016QcdNoq1rSZ4Hr5o3dCjyYmVuAB4v7VfNZTq57J/D2zPy7wLPAQJ/EZOiX4/jlJTJzFuhcXqLyMnN/Zn6vuP0a7fDZNNqqehMRFwL/EPjTUdfSj4h4E/ArwGcAMnM2M18dbVV9qQPrI6IOnEaFz7XJzG8B8z/u7kbg3uL2vcD7VrSoHixUd2Z+MzMbxd3v0D7PqW+Gfjk2Ac933d/LmARnt4jYDLwDeHi0lfTsPwH/Chi3CxC9BTgI/PeiNfWnEbFh1EX1IjNfAP4j8BywH5jKzG+Otqq+nZ+Z+6E96QHOG3E9g/inwF8vu9cCDP1yLHt5iaqLiNOBrwAfz8zDo65nORHxa8CBzHx01LUMoA68E7grM98BvEE1WwwnKfrfNwIXA38L2BAR/2S0Va0uEfFvabdlPz/I4w39coz15SUiYpJ24H8+M7866np6dBXw3oj4Ce122t+PiD8fbUk92wvszczOX1Rfpv0mMA7+AfDjzDyYmceArwJ/b8Q19euliLgAoNgeGHE9PYuIbcCvAf84BzzJytAvx9heXiLaF+v/DPB0Zn5y1PX0KjM/kZkXZuZm2r/v/5WZYzHjzMwXgecj4pJi6D2cosuLnwLPAVdGxGnFv533MCYHobvsALYVt7cB94+wlp5FxHXAvwbem5lHBn0eQ78ExcGVzuUlngbuG6PLS1wFfJD2TPmx4uuGURe1CvwL4PMR8ThwOfAHI66nJ8VfJ18Gvgf8gHaGVPayBhHxBeDbwCURsTciPgLcAfxqROym/YFOd4yyxoUsUvd/BX4O2Fn8P/1vAz23l2GQpNXDmb4krSKGviStIoa+JK0ihr4krSKGviStIoa+JK0ihr4krSL/HwFvy9X7B+kPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 166 coords\n",
      "After resolving overlaps, got 275 seqlets\n",
      "Across all tasks, the weakest transformed threshold used was: 0.8402149537634409\n",
      "MEMORY 0.334639104\n",
      "275 identified in total\n",
      "2 activity patterns with support >= 100 out of 27 possible patterns\n",
      "Metacluster sizes:  [115, 104]\n",
      "Idx to activities:  {0: '1,0,1', 1: '1,1,0'}\n",
      "MEMORY 0.334639104\n",
      "On metacluster 1\n",
      "Metacluster size 104\n",
      "Relevant tasks:  ('task0', 'task1')\n",
      "Relevant signs:  (1, 1)\n",
      "MEMORY 0.3346432\n",
      "TfModiscoSeqletsToPatternsFactory: seed=1234\n",
      "(Round 1) num seqlets: 104\n",
      "(Round 1) Computing coarse affmat\n",
      "MEMORY 0.334651392\n",
      "Beginning embedding computation\n",
      "MEMORY 0.334651392\n",
      "Computing embeddings\n",
      "MEMORY 0.334651392\n",
      "After onehot_track_fwd and onehot_track_rev\n",
      "MEMORY 0.334651392\n",
      "data_to_embed_fwd and data_to_embed_rev instantiated\n",
      "MEMORY 0.334651392\n",
      "data_to_embed_fwd and data_to_embed_rev prepared shapes are (104, 25, 4) and (104, 25, 4)\n",
      "MEMORY 0.334651392\n",
      "data_to_embed_fwd and data_to_embed_rev normalized\n",
      "MEMORY 0.334651392\n",
      "embedding_fwd and embedding_rev prepared\n",
      "MEMORY 0.443682816\n",
      "Finished embeddings computation - intermediate vars in scope\n",
      "MEMORY 0.443682816\n",
      "Finished embedding computation in 3.62 s\n",
      "MEMORY 0.443682816\n",
      "Starting affinity matrix computations\n",
      "MEMORY 0.443682816\n",
      "Finished affinity matrix computations in 0.06 s\n",
      "MEMORY 0.4436992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 104 out of 104 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Round 1) Computed coarse affmat\n",
      "MEMORY 0.352161792\n",
      "(Round 1) Computing affinity matrix on nearest neighbors\n",
      "MEMORY 0.352161792\n",
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.35350528\n",
      "Parallel runs completed\n",
      "MEMORY 0.338415616\n",
      "Job completed in: 0.86 s\n",
      "MEMORY 0.338415616\n",
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.337555456\n",
      "Parallel runs completed\n",
      "MEMORY 0.337555456\n",
      "Job completed in: 0.87 s\n",
      "MEMORY 0.337555456\n",
      "(Round 1) Computed affinity matrix on nearest neighbors in 1.97 s\n",
      "MEMORY 0.336289792\n",
      "Filtered down to 99 of 104\n",
      "(Round 1) Retained 99 rows out of 104 after filtering\n",
      "MEMORY 0.336289792\n",
      "(Round 1) Computing density adapted affmat\n",
      "MEMORY 0.336289792\n",
      "[t-SNE] Computed conditional probabilities for sample 99 / 99\n",
      "[t-SNE] Mean sigma: 0.226334\n",
      "(Round 1) Computing clustering\n",
      "MEMORY 0.336289792\n",
      "Beginning preprocessing + Louvain\n",
      "MEMORY 0.336289792\n",
      "Wrote graph to binary file in 0.0132598876953125 seconds\n",
      "MEMORY 0.336289792\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.336289792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain completed 200 runs in 7.308541774749756 seconds\n",
      "MEMORY 0.336289792\n",
      "Preparing sparse coo_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.3s finished\n",
      "200it [00:00, 2119.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared sparse coo_matrix in  0.10066509246826172 s\n",
      "MEMORY 0.336289792\n",
      "Transformed affinity matrix\n",
      "MEMORY 0.336289792\n",
      "Wrote graph to binary file in 0.008959770202636719 seconds\n",
      "MEMORY 0.336289792\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.336289792\n",
      "After 1 runs, maximum modularity is Q = 0.679919\n",
      "MEMORY 0.336289792\n",
      "After 5 runs, maximum modularity is Q = 0.69599\n",
      "MEMORY 0.336289792\n",
      "Louvain completed 55 runs in 1.1365220546722412 seconds\n",
      "MEMORY 0.336289792\n",
      "Got communities, graph, Q\n",
      "MEMORY 0.336289792\n",
      "Packaged as cluster results\n",
      "MEMORY 0.336289792\n",
      "Preproc + Louvain took 8.621917247772217 s\n",
      "MEMORY 0.336289792\n",
      "Got 7 clusters after round 1\n",
      "Counts:\n",
      "{6: 5, 1: 16, 3: 15, 4: 12, 0: 27, 2: 15, 5: 9}\n",
      "MEMORY 0.336289792\n",
      "(Round 1) Aggregating seqlets in each cluster\n",
      "MEMORY 0.336289792\n",
      "Aggregating for cluster 0 with 27 seqlets\n",
      "MEMORY 0.336289792\n",
      "Trimmed 0 out of 27\n",
      "Skipped 6 seqlets\n",
      "Aggregating for cluster 1 with 16 seqlets\n",
      "MEMORY 0.336289792\n",
      "Trimmed 1 out of 16\n",
      "Aggregating for cluster 2 with 15 seqlets\n",
      "MEMORY 0.336289792\n",
      "Trimmed 0 out of 15\n",
      "Skipped 2 seqlets\n",
      "Aggregating for cluster 3 with 15 seqlets\n",
      "MEMORY 0.336289792\n",
      "Trimmed 0 out of 15\n",
      "Skipped 1 seqlets\n",
      "Aggregating for cluster 4 with 12 seqlets\n",
      "MEMORY 0.336293888\n",
      "Trimmed 0 out of 12\n",
      "Skipped 2 seqlets\n",
      "Aggregating for cluster 5 with 9 seqlets\n",
      "MEMORY 0.336293888\n",
      "Trimmed 0 out of 9\n",
      "Aggregating for cluster 6 with 5 seqlets\n",
      "MEMORY 0.336293888\n",
      "Trimmed 0 out of 5\n",
      "(Round 2) num seqlets: 87\n",
      "(Round 2) Computing coarse affmat\n",
      "MEMORY 0.336293888\n",
      "Beginning embedding computation\n",
      "MEMORY 0.336293888\n",
      "Computing embeddings\n",
      "MEMORY 0.336293888\n",
      "After onehot_track_fwd and onehot_track_rev\n",
      "MEMORY 0.336293888\n",
      "data_to_embed_fwd and data_to_embed_rev instantiated\n",
      "MEMORY 0.336293888\n",
      "data_to_embed_fwd and data_to_embed_rev prepared shapes are (87, 25, 4) and (87, 25, 4)\n",
      "MEMORY 0.336293888\n",
      "data_to_embed_fwd and data_to_embed_rev normalized\n",
      "MEMORY 0.336293888\n",
      "embedding_fwd and embedding_rev prepared\n",
      "MEMORY 0.481718272\n",
      "Finished embeddings computation - intermediate vars in scope\n",
      "MEMORY 0.481718272\n",
      "Finished embedding computation in 2.89 s\n",
      "MEMORY 0.481718272\n",
      "Starting affinity matrix computations\n",
      "MEMORY 0.481718272\n",
      "Finished affinity matrix computations in 0.03 s\n",
      "MEMORY 0.481718272\n",
      "(Round 2) Computed coarse affmat\n",
      "MEMORY 0.481046528\n",
      "(Round 2) Computing affinity matrix on nearest neighbors\n",
      "MEMORY 0.481046528\n",
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.481325056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  87 out of  87 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel runs completed\n",
      "MEMORY 0.48216064\n",
      "Job completed in: 0.6 s\n",
      "MEMORY 0.48216064\n",
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.48216064\n",
      "Parallel runs completed\n",
      "MEMORY 0.48216064\n",
      "Job completed in: 0.63 s\n",
      "MEMORY 0.48216064\n",
      "(Round 2) Computed affinity matrix on nearest neighbors in 1.42 s\n",
      "MEMORY 0.343842816\n",
      "Not applying filtering for rounds above first round\n",
      "MEMORY 0.343842816\n",
      "(Round 2) Computing density adapted affmat\n",
      "MEMORY 0.343842816\n",
      "[t-SNE] Computed conditional probabilities for sample 87 / 87\n",
      "[t-SNE] Mean sigma: 0.230037\n",
      "(Round 2) Computing clustering\n",
      "MEMORY 0.343842816\n",
      "Beginning preprocessing + Louvain\n",
      "MEMORY 0.343842816\n",
      "Wrote graph to binary file in 0.02050924301147461 seconds\n",
      "MEMORY 0.343842816\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.343842816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain completed 200 runs in 7.3407368659973145 seconds\n",
      "MEMORY 0.343842816\n",
      "Preparing sparse coo_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.3s finished\n",
      "200it [00:00, 2255.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared sparse coo_matrix in  0.09506773948669434 s\n",
      "MEMORY 0.343842816\n",
      "Transformed affinity matrix\n",
      "MEMORY 0.343842816\n",
      "Wrote graph to binary file in 0.00486302375793457 seconds\n",
      "MEMORY 0.343842816\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.343842816\n",
      "After 1 runs, maximum modularity is Q = 0.764153\n",
      "MEMORY 0.343842816\n",
      "Louvain completed 51 runs in 1.0230498313903809 seconds\n",
      "MEMORY 0.343842816\n",
      "Got communities, graph, Q\n",
      "MEMORY 0.343842816\n",
      "Packaged as cluster results\n",
      "MEMORY 0.343842816\n",
      "Preproc + Louvain took 8.536100149154663 s\n",
      "MEMORY 0.343842816\n",
      "Got 10 clusters after round 2\n",
      "Counts:\n",
      "{5: 10, 6: 8, 7: 6, 0: 15, 4: 10, 2: 10, 8: 5, 9: 2, 3: 10, 1: 11}\n",
      "MEMORY 0.343842816\n",
      "(Round 2) Aggregating seqlets in each cluster\n",
      "MEMORY 0.343842816\n",
      "Aggregating for cluster 0 with 15 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 2 out of 15\n",
      "Aggregating for cluster 1 with 11 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 11\n",
      "Aggregating for cluster 2 with 10 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 10\n",
      "Aggregating for cluster 3 with 10 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 10\n",
      "Aggregating for cluster 4 with 10 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 10\n",
      "Aggregating for cluster 5 with 10 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 2 out of 10\n",
      "Aggregating for cluster 6 with 8 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 8\n",
      "Aggregating for cluster 7 with 6 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 6\n",
      "Aggregating for cluster 8 with 5 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 5\n",
      "Aggregating for cluster 9 with 2 seqlets\n",
      "MEMORY 0.343842816\n",
      "Trimmed 0 out of 2\n",
      "Got 10 clusters\n",
      "Splitting into subclusters...\n",
      "MEMORY 0.343842816\n",
      "Merging on 10 clusters\n",
      "MEMORY 0.343842816\n",
      "On merging iteration 1\n",
      "Computing pattern to seqlet distances\n",
      "Computing pattern to seqlet distances took 0.4188871383666992 s\n",
      "Computing pattern to pattern distances\n",
      "Collapsing 0 & 4 with prob 4.37291618685103e-05 and sim 1.9503740885351395\n",
      "Collapsing 0 & 1 with prob 6.830020343087511e-06 and sim 1.9385035126382142\n",
      "Collapsing 0 & 8 with prob 2.317623077149091e-05 and sim 1.9312167477209932\n",
      "Collapsing 0 & 3 with prob 6.020801720836262e-05 and sim 1.92809267808359\n",
      "Collapsing 1 & 4 with prob 2.584880019387114e-06 and sim 1.9262230065336639\n",
      "Collapsing 3 & 4 with prob 3.5461702097761987e-05 and sim 1.9146000508921683\n",
      "Collapsing 0 & 7 with prob 2.9588673116987283e-06 and sim 1.9138941343502278\n",
      "Collapsing 0 & 6 with prob 2.0564569933231455e-06 and sim 1.91242965703532\n",
      "Collapsing 2 & 5 with prob 1.3867664711344494e-05 and sim 1.9108462512286892\n",
      "Collapsing 3 & 6 with prob 3.5841235926946777e-06 and sim 1.9058978053285522\n",
      "Collapsing 3 & 8 with prob 0.00013548796454263324 and sim 1.9056808764856799\n",
      "Collapsing 4 & 7 with prob 4.412237879389978e-06 and sim 1.8953483145041397\n",
      "Collapsing 4 & 6 with prob 2.214674287635875e-06 and sim 1.8930713367436565\n",
      "Collapsing 4 & 8 with prob 5.46910562523367e-06 and sim 1.8832554127658243\n",
      "Collapsing 7 & 8 with prob 1.3524227036041007e-05 and sim 1.8764011926075617\n",
      "Collapsing 4 & 5 with prob 3.058273802087253e-05 and sim 1.8760167228143731\n",
      "Collapsing 5 & 8 with prob 5.086568622970852e-06 and sim 1.8758288961183929\n",
      "Collapsing 2 & 3 with prob 2.627160236074976e-05 and sim 1.8592450327776493\n",
      "Collapsing 2 & 8 with prob 7.410108871941937e-06 and sim 1.8591895749083855\n",
      "Collapsing 3 & 7 with prob 9.220308683669153e-06 and sim 1.8556416227900099\n",
      "Collapsing 2 & 4 with prob 1.2669975942002414e-05 and sim 1.8537253452321893\n",
      "Collapsing 0 & 5 with prob 1.3922793663107826e-05 and sim 1.8454185992687255\n",
      "Collapsing 0 & 2 with prob 1.3109966215578505e-05 and sim 1.8307576673859436\n",
      "Collapsing 3 & 5 with prob 9.941737258712937e-06 and sim 1.816617289570315\n",
      "Collapsing 5 & 7 with prob 1.5274003900763792e-06 and sim 1.801940686318272\n",
      "Trimmed 0 out of 23\n",
      "Trimmed 0 out of 33\n",
      "Trimmed 5 out of 38\n",
      "Trimmed 0 out of 43\n",
      "Trimmed 4 out of 47\n",
      "Trimmed 8 out of 51\n",
      "Trimmed 0 out of 18\n",
      "Trimmed 0 out of 61\n",
      "On merging iteration 2\n",
      "Computing pattern to seqlet distances\n",
      "Computing pattern to seqlet distances took 0.32022786140441895 s\n",
      "Computing pattern to pattern distances\n",
      "Got 2 patterns after merging\n",
      "MEMORY 0.337330176\n",
      "Performing seqlet reassignment\n",
      "MEMORY 0.337330176\n",
      "Cross contin jaccard time taken: 0.0 s\n",
      "Cross contin jaccard time taken: 0.0 s\n",
      "Got 1 patterns after reassignment\n",
      "MEMORY 0.337330176\n",
      "Total time taken is 30.84s\n",
      "MEMORY 0.337330176\n",
      "On metacluster 0\n",
      "Metacluster size 115\n",
      "Relevant tasks:  ('task0', 'task2')\n",
      "Relevant signs:  (1, 1)\n",
      "MEMORY 0.337330176\n",
      "TfModiscoSeqletsToPatternsFactory: seed=1234\n",
      "(Round 1) num seqlets: 115\n",
      "(Round 1) Computing coarse affmat\n",
      "MEMORY 0.337330176\n",
      "Beginning embedding computation\n",
      "MEMORY 0.337330176\n",
      "Computing embeddings\n",
      "MEMORY 0.337330176\n",
      "After onehot_track_fwd and onehot_track_rev\n",
      "MEMORY 0.337330176\n",
      "data_to_embed_fwd and data_to_embed_rev instantiated\n",
      "MEMORY 0.337330176\n",
      "data_to_embed_fwd and data_to_embed_rev prepared shapes are (115, 25, 4) and (115, 25, 4)\n",
      "MEMORY 0.337330176\n",
      "data_to_embed_fwd and data_to_embed_rev normalized\n",
      "MEMORY 0.337330176\n",
      "embedding_fwd and embedding_rev prepared\n",
      "MEMORY 0.443015168\n",
      "Finished embeddings computation - intermediate vars in scope\n",
      "MEMORY 0.443015168\n",
      "Finished embedding computation in 3.68 s\n",
      "MEMORY 0.443015168\n",
      "Starting affinity matrix computations\n",
      "MEMORY 0.443015168\n",
      "Finished affinity matrix computations in 0.05 s\n",
      "MEMORY 0.443785216\n",
      "(Round 1) Computed coarse affmat\n",
      "MEMORY 0.443052032\n",
      "(Round 1) Computing affinity matrix on nearest neighbors\n",
      "MEMORY 0.443052032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 115 out of 115 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.444157952\n",
      "Parallel runs completed\n",
      "MEMORY 0.348094464\n",
      "Job completed in: 1.01 s\n",
      "MEMORY 0.348094464\n",
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.343793664\n",
      "Parallel runs completed\n",
      "MEMORY 0.343814144\n",
      "Job completed in: 1.03 s\n",
      "MEMORY 0.343814144\n",
      "(Round 1) Computed affinity matrix on nearest neighbors in 2.26 s\n",
      "MEMORY 0.338808832\n",
      "Filtered down to 109 of 115\n",
      "(Round 1) Retained 109 rows out of 115 after filtering\n",
      "MEMORY 0.338808832\n",
      "(Round 1) Computing density adapted affmat\n",
      "MEMORY 0.338808832\n",
      "[t-SNE] Computed conditional probabilities for sample 109 / 109\n",
      "[t-SNE] Mean sigma: 0.219531\n",
      "(Round 1) Computing clustering\n",
      "MEMORY 0.338808832\n",
      "Beginning preprocessing + Louvain\n",
      "MEMORY 0.338808832\n",
      "Wrote graph to binary file in 0.011185884475708008 seconds\n",
      "MEMORY 0.338808832\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.338812928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain completed 200 runs in 7.322318077087402 seconds\n",
      "MEMORY 0.338812928\n",
      "Preparing sparse coo_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.3s finished\n",
      "200it [00:00, 1944.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared sparse coo_matrix in  0.10840296745300293 s\n",
      "MEMORY 0.338812928\n",
      "Transformed affinity matrix\n",
      "MEMORY 0.338812928\n",
      "Wrote graph to binary file in 0.007862091064453125 seconds\n",
      "MEMORY 0.338812928\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.338812928\n",
      "After 1 runs, maximum modularity is Q = 0.678165\n",
      "MEMORY 0.338812928\n",
      "After 2 runs, maximum modularity is Q = 0.680689\n",
      "MEMORY 0.338812928\n",
      "After 3 runs, maximum modularity is Q = 0.698542\n",
      "MEMORY 0.338812928\n",
      "Louvain completed 53 runs in 1.1024887561798096 seconds\n",
      "MEMORY 0.338812928\n",
      "Got communities, graph, Q\n",
      "MEMORY 0.338812928\n",
      "Packaged as cluster results\n",
      "MEMORY 0.338812928\n",
      "Preproc + Louvain took 8.618950843811035 s\n",
      "MEMORY 0.338812928\n",
      "Got 6 clusters after round 1\n",
      "Counts:\n",
      "{2: 21, 1: 22, 4: 18, 0: 25, 3: 20, 5: 3}\n",
      "MEMORY 0.338812928\n",
      "(Round 1) Aggregating seqlets in each cluster\n",
      "MEMORY 0.338812928\n",
      "Aggregating for cluster 0 with 25 seqlets\n",
      "MEMORY 0.338812928\n",
      "Trimmed 0 out of 25\n",
      "Skipped 3 seqlets\n",
      "Aggregating for cluster 1 with 22 seqlets\n",
      "MEMORY 0.338812928\n",
      "Trimmed 2 out of 22\n",
      "Skipped 3 seqlets\n",
      "Aggregating for cluster 2 with 21 seqlets\n",
      "MEMORY 0.338812928\n",
      "Trimmed 0 out of 21\n",
      "Skipped 6 seqlets\n",
      "Aggregating for cluster 3 with 20 seqlets\n",
      "MEMORY 0.338812928\n",
      "Trimmed 3 out of 20\n",
      "Skipped 2 seqlets\n",
      "Aggregating for cluster 4 with 18 seqlets\n",
      "MEMORY 0.338812928\n",
      "Trimmed 0 out of 18\n",
      "Skipped 3 seqlets\n",
      "Aggregating for cluster 5 with 3 seqlets\n",
      "MEMORY 0.338812928\n",
      "Trimmed 0 out of 3\n",
      "(Round 2) num seqlets: 86\n",
      "(Round 2) Computing coarse affmat\n",
      "MEMORY 0.338812928\n",
      "Beginning embedding computation\n",
      "MEMORY 0.338812928\n",
      "Computing embeddings\n",
      "MEMORY 0.338812928\n",
      "After onehot_track_fwd and onehot_track_rev\n",
      "MEMORY 0.338812928\n",
      "data_to_embed_fwd and data_to_embed_rev instantiated\n",
      "MEMORY 0.338812928\n",
      "data_to_embed_fwd and data_to_embed_rev prepared shapes are (86, 25, 4) and (86, 25, 4)\n",
      "MEMORY 0.338812928\n",
      "data_to_embed_fwd and data_to_embed_rev normalized\n",
      "MEMORY 0.338812928\n",
      "embedding_fwd and embedding_rev prepared\n",
      "MEMORY 0.472633344\n",
      "Finished embeddings computation - intermediate vars in scope\n",
      "MEMORY 0.472633344\n",
      "Finished embedding computation in 2.89 s\n",
      "MEMORY 0.472633344\n",
      "Starting affinity matrix computations\n",
      "MEMORY 0.472633344\n",
      "Finished affinity matrix computations in 0.03 s\n",
      "MEMORY 0.472633344\n",
      "(Round 2) Computed coarse affmat\n",
      "MEMORY 0.471781376\n",
      "(Round 2) Computing affinity matrix on nearest neighbors\n",
      "MEMORY 0.471781376\n",
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.472211456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  86 out of  86 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel runs completed\n",
      "MEMORY 0.47304704\n",
      "Job completed in: 0.63 s\n",
      "MEMORY 0.47304704\n",
      "Launching nearest neighbors affmat calculation job\n",
      "MEMORY 0.47304704\n",
      "Parallel runs completed\n",
      "MEMORY 0.47304704\n",
      "Job completed in: 0.62 s\n",
      "MEMORY 0.47304704\n",
      "(Round 2) Computed affinity matrix on nearest neighbors in 1.45 s\n",
      "MEMORY 0.363446272\n",
      "Not applying filtering for rounds above first round\n",
      "MEMORY 0.363446272\n",
      "(Round 2) Computing density adapted affmat\n",
      "MEMORY 0.363446272\n",
      "[t-SNE] Computed conditional probabilities for sample 86 / 86\n",
      "[t-SNE] Mean sigma: 0.223133\n",
      "(Round 2) Computing clustering\n",
      "MEMORY 0.363446272\n",
      "Beginning preprocessing + Louvain\n",
      "MEMORY 0.363446272\n",
      "Wrote graph to binary file in 0.008213996887207031 seconds\n",
      "MEMORY 0.363446272\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.363446272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain completed 200 runs in 7.242902994155884 seconds\n",
      "MEMORY 0.363446272\n",
      "Preparing sparse coo_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.2s finished\n",
      "200it [00:00, 2170.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared sparse coo_matrix in  0.0976247787475586 s\n",
      "MEMORY 0.363446272\n",
      "Transformed affinity matrix\n",
      "MEMORY 0.363446272\n",
      "Wrote graph to binary file in 0.005459785461425781 seconds\n",
      "MEMORY 0.363446272\n",
      "Running Louvain modularity optimization\n",
      "MEMORY 0.363446272\n",
      "After 1 runs, maximum modularity is Q = 0.700257\n",
      "MEMORY 0.363446272\n",
      "After 5 runs, maximum modularity is Q = 0.709545\n",
      "MEMORY 0.363446272\n",
      "Louvain completed 55 runs in 1.1324641704559326 seconds\n",
      "MEMORY 0.363446272\n",
      "Got communities, graph, Q\n",
      "MEMORY 0.363446272\n",
      "Packaged as cluster results\n",
      "MEMORY 0.363446272\n",
      "Preproc + Louvain took 8.539399862289429 s\n",
      "MEMORY 0.363446272\n",
      "Got 5 clusters after round 2\n",
      "Counts:\n",
      "{2: 19, 1: 21, 4: 8, 0: 22, 3: 16}\n",
      "MEMORY 0.363446272\n",
      "(Round 2) Aggregating seqlets in each cluster\n",
      "MEMORY 0.363446272\n",
      "Aggregating for cluster 0 with 22 seqlets\n",
      "MEMORY 0.363446272\n",
      "Trimmed 0 out of 22\n",
      "Aggregating for cluster 1 with 21 seqlets\n",
      "MEMORY 0.363446272\n",
      "Trimmed 1 out of 21\n",
      "Aggregating for cluster 2 with 19 seqlets\n",
      "MEMORY 0.363446272\n",
      "Trimmed 0 out of 19\n",
      "Aggregating for cluster 3 with 16 seqlets\n",
      "MEMORY 0.363446272\n",
      "Trimmed 0 out of 16\n",
      "Aggregating for cluster 4 with 8 seqlets\n",
      "MEMORY 0.363446272\n",
      "Trimmed 0 out of 8\n",
      "Got 5 clusters\n",
      "Splitting into subclusters...\n",
      "MEMORY 0.363446272\n",
      "Merging on 5 clusters\n",
      "MEMORY 0.363446272\n",
      "On merging iteration 1\n",
      "Computing pattern to seqlet distances\n",
      "Computing pattern to seqlet distances took 0.3873462677001953 s\n",
      "Computing pattern to pattern distances\n",
      "Collapsing 0 & 1 with prob 0.0002823974369117803 and sim 1.9456035066295068\n",
      "Collapsing 1 & 2 with prob 0.0002455653705628902 and sim 1.9415756539583977\n",
      "Collapsing 1 & 4 with prob 4.912708090606337e-05 and sim 1.9321966247133013\n",
      "Collapsing 2 & 3 with prob 1.635773041794524e-05 and sim 1.9310862151106551\n",
      "Collapsing 2 & 4 with prob 3.037938278838355e-05 and sim 1.9185880721393045\n",
      "Collapsing 1 & 3 with prob 4.124908397148514e-05 and sim 1.9181464403437107\n",
      "Collapsing 0 & 4 with prob 1.5862869295841177e-05 and sim 1.9114950512459765\n",
      "Collapsing 3 & 4 with prob 3.3845203550498993e-06 and sim 1.9045441884755516\n",
      "Collapsing 0 & 2 with prob 3.2040278518216247e-05 and sim 1.9031286588372838\n",
      "Collapsing 0 & 3 with prob 3.2036986451441582e-06 and sim 1.8698286992185305\n",
      "Trimmed 0 out of 42\n",
      "Trimmed 0 out of 61\n",
      "Trimmed 0 out of 69\n",
      "Trimmed 1 out of 85\n",
      "On merging iteration 2\n",
      "Computing pattern to seqlet distances\n",
      "Computing pattern to seqlet distances took 0.32068514823913574 s\n",
      "Computing pattern to pattern distances\n",
      "Got 1 patterns after merging\n",
      "MEMORY 0.36345856\n",
      "Performing seqlet reassignment\n",
      "MEMORY 0.36345856\n",
      "Skipped 2 seqlets\n",
      "Got 1 patterns after reassignment\n",
      "MEMORY 0.36345856\n",
      "Total time taken is 30.94s\n",
      "MEMORY 0.36345856\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import h5py\n",
    "import numpy as np\n",
    "import modisco\n",
    "import modisco.cluster.phenograph.core\n",
    "reload(modisco.cluster.phenograph.core)\n",
    "import modisco.cluster.phenograph.cluster\n",
    "reload(modisco.cluster.phenograph.cluster)\n",
    "import modisco.cluster.phenograph\n",
    "reload(modisco.cluster.phenograph)\n",
    "import modisco.aggregator\n",
    "reload(modisco.aggregator)\n",
    "import modisco.cluster.core\n",
    "reload(modisco.cluster.core)\n",
    "import modisco.cluster\n",
    "reload(modisco.cluster)\n",
    "import modisco.affinitymat.core\n",
    "reload(modisco.affinitymat.core)\n",
    "import modisco.affinitymat.transformers\n",
    "reload(modisco.affinitymat.transformers)\n",
    "import modisco.tfmodisco_workflow.seqlets_to_patterns\n",
    "reload(modisco.tfmodisco_workflow.seqlets_to_patterns)\n",
    "import modisco.tfmodisco_workflow.workflow\n",
    "reload(modisco.tfmodisco_workflow.workflow)\n",
    "\n",
    "null_per_pos_scores = modisco.coordproducers.LaplaceNullDist(num_to_samp=5000)\n",
    "tfmodisco_results = modisco.tfmodisco_workflow.workflow.TfModiscoWorkflow(\n",
    "                    #Slight modifications from the default settings\n",
    "                    sliding_window_size=15,\n",
    "                    flank_size=5,\n",
    "                    target_seqlet_fdr=0.15,\n",
    "                    seqlets_to_patterns_factory=\n",
    "                     modisco.tfmodisco_workflow.seqlets_to_patterns.TfModiscoSeqletsToPatternsFactory(\n",
    "                        trim_to_window_size=15,\n",
    "                        initial_flank_to_add=5,\n",
    "                        kmer_len=5, num_gaps=1,\n",
    "                        num_mismatches=0,\n",
    "                        final_min_cluster_size=60,\n",
    "                        n_cores=1)\n",
    "                )(\n",
    "                 task_names=[\"task0\", \"task1\", \"task2\"],\n",
    "                 contrib_scores=task_to_scores,\n",
    "                 hypothetical_contribs=task_to_hyp_scores,\n",
    "                 one_hot=onehot_data,\n",
    "                 null_per_pos_scores = null_per_pos_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibQhUzCN_S0j"
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAOto6Yx-5qD"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import modisco.util\n",
    "reload(modisco.util)\n",
    "![[ -e results.hdf5 ]] && rm results.hdf5\n",
    "grp = h5py.File(\"results.hdf5\")\n",
    "tfmodisco_results.save_hdf5(grp)\n",
    "grp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxjUsY4B_Zcf"
   },
   "source": [
    "## Print results directly from hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SvRgsV6D_WYR",
    "outputId": "2bfc41ab-d0d3-4dde-b8fb-a39515e8176f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from modisco.visualization import viz_sequence\n",
    "reload(viz_sequence)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import modisco.affinitymat.core\n",
    "reload(modisco.affinitymat.core)\n",
    "import modisco.cluster.phenograph.core\n",
    "reload(modisco.cluster.phenograph.core)\n",
    "import modisco.cluster.phenograph.cluster\n",
    "reload(modisco.cluster.phenograph.cluster)\n",
    "import modisco.cluster.core\n",
    "reload(modisco.cluster.core)\n",
    "import modisco.aggregator\n",
    "reload(modisco.aggregator)\n",
    "\n",
    "hdf5_results = h5py.File(\"results.hdf5\",\"r\")\n",
    "\n",
    "print(\"Metaclusters heatmap\")\n",
    "import seaborn as sns\n",
    "activity_patterns = np.array(hdf5_results['metaclustering_results']['attribute_vectors'])[\n",
    "                    np.array(\n",
    "        [x[0] for x in sorted(\n",
    "                enumerate(hdf5_results['metaclustering_results']['metacluster_indices']),\n",
    "               key=lambda x: x[1])])]\n",
    "sns.heatmap(activity_patterns, center=0)\n",
    "plt.show()\n",
    "\n",
    "metacluster_names = [\n",
    "    x.decode(\"utf-8\") for x in \n",
    "    list(hdf5_results[\"metaclustering_results\"]\n",
    "         [\"all_metacluster_names\"][:])]\n",
    "\n",
    "all_patterns = []\n",
    "background = np.array([0.27, 0.23, 0.23, 0.27])\n",
    "\n",
    "for metacluster_name in metacluster_names:\n",
    "    print(metacluster_name)\n",
    "    metacluster_grp = (hdf5_results[\"metacluster_idx_to_submetacluster_results\"]\n",
    "                                   [metacluster_name])\n",
    "    print(\"activity pattern:\",metacluster_grp[\"activity_pattern\"][:])\n",
    "    all_pattern_names = [x.decode(\"utf-8\") for x in \n",
    "                         list(metacluster_grp[\"seqlets_to_patterns_result\"]\n",
    "                                             [\"patterns\"][\"all_pattern_names\"][:])]\n",
    "    if (len(all_pattern_names)==0):\n",
    "        print(\"No motifs found for this activity pattern\")\n",
    "    for pattern_name in all_pattern_names:\n",
    "        print(metacluster_name, pattern_name)\n",
    "        all_patterns.append((metacluster_name, pattern_name))\n",
    "        pattern = metacluster_grp[\"seqlets_to_patterns_result\"][\"patterns\"][pattern_name]\n",
    "        print(\"total seqlets:\",len(pattern[\"seqlets_and_alnmts\"][\"seqlets\"]))\n",
    "        print(\"Task 0 hypothetical scores:\")\n",
    "        viz_sequence.plot_weights(pattern[\"task0_hypothetical_contribs\"][\"fwd\"])\n",
    "        print(\"Task 0 actual importance scores:\")\n",
    "        viz_sequence.plot_weights(pattern[\"task0_contrib_scores\"][\"fwd\"])\n",
    "        print(\"Task 1 hypothetical scores:\")\n",
    "        viz_sequence.plot_weights(pattern[\"task1_hypothetical_contribs\"][\"fwd\"])\n",
    "        print(\"Task 1 actual importance scores:\")\n",
    "        viz_sequence.plot_weights(pattern[\"task1_contrib_scores\"][\"fwd\"])\n",
    "        print(\"Task 2 hypothetical scores:\")\n",
    "        viz_sequence.plot_weights(pattern[\"task2_hypothetical_contribs\"][\"fwd\"])\n",
    "        print(\"Task 2 actual importance scores:\")\n",
    "        viz_sequence.plot_weights(pattern[\"task2_contrib_scores\"][\"fwd\"])\n",
    "        print(\"onehot, fwd and rev:\")\n",
    "        viz_sequence.plot_weights(viz_sequence.ic_scale(np.array(pattern[\"sequence\"][\"fwd\"]),\n",
    "                                                        background=background)) \n",
    "        viz_sequence.plot_weights(viz_sequence.ic_scale(np.array(pattern[\"sequence\"][\"rev\"]),\n",
    "                                                        background=background)) \n",
    "        \n",
    "hdf5_results.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFQSYr9q_qI9"
   },
   "source": [
    "## Load the saved hdf5 file\n",
    "Load the results object from the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVtrMZ9o_mu0"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import modisco\n",
    "from modisco.tfmodisco_workflow import workflow\n",
    "\n",
    "track_set = modisco.tfmodisco_workflow.workflow.prep_track_set(\n",
    "                task_names=tasks,\n",
    "                contrib_scores=task_to_scores,\n",
    "                hypothetical_contribs=task_to_hyp_scores,\n",
    "                one_hot=onehot_data)\n",
    "\n",
    "grp = h5py.File(\"results.hdf5\",\"r\")\n",
    "loaded_tfmodisco_results =\\\n",
    "    workflow.TfModiscoResults.from_hdf5(grp, track_set=track_set)\n",
    "grp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90lxFiCd_4c-"
   },
   "source": [
    "## Do hit scoring\n",
    "The hit scoring strategy is still in development. For the previous hit scoring strategy, see the version at tag [v0.5.3.1](https://colab.research.google.com/github/kundajelab/tfmodisco/blob/v0.5.3.1/examples/simulated_TAL_GATA_deeplearning/(On_Google_Colab)_With_Hit_Scoring_TF_MoDISco_TAL_GATA.ipynb)\n",
    "\n",
    "### Trim the motifs by information content\n",
    "\n",
    "Before scanning the sequence for hits to motifs, it is worth trimming the motifs by their information content. Let's demonstrate scanning for the GATA motif. We will first trim the motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "cxu4zoH90kZr",
    "outputId": "fa5c3701-cef6-4657-fb9e-56be25a52ad7"
   },
   "outputs": [],
   "source": [
    "untrimmed_gata_pattern = (\n",
    "    loaded_tfmodisco_results\n",
    "    .metacluster_idx_to_submetacluster_results[\"metacluster_1\"]\n",
    "    .seqlets_to_patterns_result.patterns[0])\n",
    "print(\"Untrimmed Gata - sequence (scaled by information content)\")\n",
    "viz_sequence.plot_weights(viz_sequence.ic_scale(untrimmed_gata_pattern[\"sequence\"].fwd, background=background))\n",
    "print(\"Untrimmed Gata - task 0 hypothetical scores\")\n",
    "viz_sequence.plot_weights(untrimmed_gata_pattern[\"task0_hypothetical_contribs\"].fwd)\n",
    "trimmed_gata = untrimmed_gata_pattern.trim_by_ic(ppm_track_name=\"sequence\",\n",
    "                                                 background=background,\n",
    "                                                 threshold=0.3)\n",
    "print(\"IC-trimmed Gata - sequence (scaled by information content)\")\n",
    "viz_sequence.plot_weights(viz_sequence.ic_scale(trimmed_gata[\"sequence\"].fwd, background=background))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PwuFV-ZG0kZu"
   },
   "source": [
    "Trimming the 45bp GATA motif by information content selected the 9bp subsequence in the range 19-28. Note that the original GATA motif used in the simulation was 10bp long (GATA_disc1 at http://compbio.mit.edu/encode-motifs/ ). Trimming discarded the very first position of that motif, at which there is a weak preference for G followed by A, C and T. Indeed, when we look at the hypothetical importance scores of the untrimmed GATA motif, we see that at position 18 the network has indeed learned a preference for G followed by A, C and T, and that this preference is not apparent when looking at the sequence motif. This reveals an advantage of using the hypothetical importance scores; they can show us the preference of the network even for bases that aren't present in the underlying sequence. In the future, a more principled approaches to doing the trimming based on the hypothetical importance scores could be developed. For now, we will proceed with the version of the motif that has been trimmed by information content.\n",
    "\n",
    "### Perform scanning with the trimmed motif\n",
    "\n",
    "Having trimmed the motif, we will scan the importance score tracks with it. We will compute two kinds of scores. The first (\"masked hCWM cosine similariy\") measures the similarity of the importance scores to the motif (irrespective of the magnitude of the scores), and the second measures the total importance within the window of the motif. Information from both scores will be used to call hits.\n",
    "\n",
    "#### Masked hCWM cosine similarity\n",
    "\n",
    "The masked hCWM cosine similarity is used to gauge the similarity between a TF-MoDISco motif and the contribution scores present at a given window of the input sequence, irrespective of the magnitude of the scores. It is best illustrated with an example. Consider the GATA hypothetical contribution weight matrix (hereby referred to as the hCWM) below (the exact values may not be up to date with the rest of the notebook but are meant to be illustrative):\n",
    "```\n",
    ">>> print(trimmed_gata[\"task0_hypothetical_contribs\"].fwd)\n",
    "[[-0.03782349  0.09118378  0.070142   -0.12350229]\n",
    " [ 0.1215808  -0.08301942 -0.09632582  0.05776444]\n",
    " [-0.1386668  -0.10839121  0.2793305  -0.03227249]\n",
    " [ 0.34087033 -0.20777264 -0.02217297 -0.11092472]\n",
    " [-0.01404373 -0.21645161 -0.04688007  0.27737541]\n",
    " [ 0.1804657  -0.184394   -0.0562734   0.0602017 ]\n",
    " [ 0.24564405 -0.04153355 -0.09036025 -0.11375025]\n",
    " [-0.23648668  0.09994425  0.25375557 -0.11721314]\n",
    " [ 0.05861893  0.04707453  0.10303728 -0.20873074]]\n",
    "```\n",
    "\n",
    "Imagine we wanted to use this to score the sequence `CCGATTCGG`. We could take the cosine similarity between the GATA hCWM and the hypothetical importance scores at `CCGATTCGG`. Empirically, however, we have found that over-reliance on hypothetical importance scores - without grounding in the bases that are actually present in the sequence - can yield false positives. We could take the cosine similarity between the GATA hCWM and the actual contribution scores at `CCGATTCGG`, but this is an unsatisfactory solution because the actual contribution scores at `CCGATTCGG` only have nonzero values at the bases that are actually present at each position in the sequence, whereas the GATA hCWM has nonzero values for all bases at all positions. Instead, we *mask* the hCWM to only consider the bases corresponding to `CCGATTCGG`. Concretely, when scannign the sequence `CCGATTCGG`, we use the following masked hCWM:\n",
    "\n",
    "```\n",
    "[[ 0.0         0.09118378  0.0         0.0       ]\n",
    " [ 0.0        -0.08301942  0.0         0.0       ]\n",
    " [ 0.0         0.0         0.2793305   0.0       ]\n",
    " [ 0.34087033  0.0         0.0         0.0       ]\n",
    " [ 0.0         0.0         0.0         0.27737541]\n",
    " [ 0.0         0.0         0.0         0.0602017 ]\n",
    " [ 0.0        -0.04153355  0.0         0.0       ]\n",
    " [ 0.0         0.0         0.25375557  0.0       ]\n",
    " [ 0.0         0.0         0.10303728  0.0       ]]\n",
    "```\n",
    "Our similarity score for `CCGATTCGG` will then be the cosine similarity between the masked hCWM above and the contribution scores present at `CCGATTCGG`. The masking is done separately for each window scanned. You can refer to the code for how this is achieved efficiently using numpy stride tricks.\n",
    "\n",
    "#### Sum of scores in window\n",
    "\n",
    "This simply consists of taking the sum of the contribution scores in a given window of the input sequence. Looking at the total contribution is useful for identifying motif hits that may look like a good match if you only considered the local sequence, but which may not in fact be strongly bound by the TF because the sequence does not have the requisite cofactor motifs. For example, imagine both TAL and GATA need to be present in order for either TF to bind strongly (this logic is encapsulated in prediction task 0 in the simulation, which is a 1 iff both TAL and GATA are present, and a 0 otherwise). Even though a given portion of the sequence may be an excellent match to the GATA motif, we may not want to consider it a strong motif hit if the TAL motif is not also present in the surrounding sequence. The idea is that the neural network will have learned this logic and will give GATA motifs less importance for task 0 if they are present in a sequence that does not also have TAL. We will see an example of this below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0BevaQ2AkD4"
   },
   "outputs": [],
   "source": [
    "#compute the masked hCWM cosine similarity.\n",
    "#In the TAL-GATA simulation, only the forward versions of\n",
    "# the motifs had been embedded for simplicity. But for demonstration purposes, we will scan\n",
    "# for both the fwd and reverse motif.\n",
    "#We will use the scores for task 0, which is a 1 iff both the TAL (CAGATG) and GATA (GATAAG)\n",
    "# motifs are present in the sequence.\n",
    "imp_scores = np.array(task_to_scores[\"task0\"])\n",
    "onehot_seq = np.array(onehot_data)\n",
    "fwd_masked_cosine_sim = modisco.util.compute_masked_cosine_sim(\n",
    "                                     imp_scores=imp_scores,\n",
    "                                     onehot_seq=onehot_seq,\n",
    "                                     weightmat=trimmed_gata[\"task0_hypothetical_contribs\"].fwd)\n",
    "rev_masked_cosine_sim = modisco.util.compute_masked_cosine_sim(\n",
    "                                     imp_scores=imp_scores,\n",
    "                                     onehot_seq=onehot_seq,\n",
    "                                     weightmat=trimmed_gata[\"task0_hypothetical_contribs\"].rev)\n",
    "\n",
    "#We take the max of the masked_cosine_sim on the fwd and reverse strands\n",
    "is_fwd_masked_cosine_sim = fwd_masked_cosine_sim > rev_masked_cosine_sim\n",
    "masked_cosine_sim = (fwd_masked_cosine_sim*is_fwd_masked_cosine_sim\n",
    "                     + rev_masked_cosine_sim*(is_fwd_masked_cosine_sim==False))\n",
    "\n",
    "#Also look at the total sum of scores in each window\n",
    "sum_scores = modisco.util.compute_sum_scores(imp_scores=imp_scores,\n",
    "                                             window_size=len(trimmed_gata[\"task0_hypothetical_contribs\"].fwd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uKypa3xI0kZw"
   },
   "source": [
    "Visualize the 2-d scatterplot for both masked_cosine_sim and sum_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "6hwvQ1dA0kZx",
    "outputId": "a1d06557-799f-4255-e1fa-9f1064bb6fc6"
   },
   "outputs": [],
   "source": [
    "#note that if you have a large number of datapoints here, you would likely want to subsample\n",
    "# from the arrays. This can be achieved with, e.g. masked_cosine_sim.ravel()[::sumsample_factor]\n",
    "# you may also want to decrease alpha on the scatterplot. In matplotlib, alpha can be as low as 0.002\n",
    "plt.scatter(masked_cosine_sim.ravel(), sum_scores.ravel(), alpha=0.1)\n",
    "plt.xlabel(\"Masked cosine similarity\")\n",
    "plt.ylabel(\"Sum score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWBrnbZ30kZz"
   },
   "source": [
    "To decide where to draw the threshold, it is useful to visualize the 1-d histogram for \"masked_cosine_sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "8ZG2kwYD0kZ0",
    "outputId": "71dc0ea2-1bbb-430f-c2a2-a6087d834b4f"
   },
   "outputs": [],
   "source": [
    "plt.hist(masked_cosine_sim.ravel(), bins=100, density=True)\n",
    "plt.xlabel(\"Masked cosine similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGL8LocN0kZ2"
   },
   "source": [
    "It looks like a threshold of around 0.85 would work well for the \"masked cosine similarity axis\". Applying this threshold and then looking at the distribution for \"sum scores\" yields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "7rU98aJk0kZ3",
    "outputId": "2c4d6f19-3c6e-4ce1-ea26-952a263e1c59"
   },
   "outputs": [],
   "source": [
    "masked_cosine_sim_thresh = 0.85\n",
    "plt.hist(sum_scores.ravel()[masked_cosine_sim.ravel() > masked_cosine_sim_thresh],\n",
    "         bins=20, density=True)\n",
    "plt.xlabel(\"Sum scores\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHKHY3mq0kZ5"
   },
   "source": [
    "The best choice of threshold is an open research question and depends on how strong you would like the matches to be. For demonstration purposes, we will use the threshold of 2 on sum_scores, which is on the stringent side. The threshold of 2 might miss what could be considered \"weak affinity\" binding sites. Let us visualize the retained hits on a 2d scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "IME4TNtF0kZ7",
    "outputId": "ca93c898-e3a9-411e-f6ce-2f7b5cccbfd8"
   },
   "outputs": [],
   "source": [
    "sum_score_thresh = 2\n",
    "threshold_passers = ((masked_cosine_sim > masked_cosine_sim_thresh)*\n",
    "                     (sum_scores > sum_score_thresh))\n",
    "handles = []\n",
    "handles.append(\n",
    "    plt.scatter(masked_cosine_sim[threshold_passers==False].ravel(),\n",
    "            sum_scores[threshold_passers==False].ravel(), alpha=0.1))\n",
    "handles.append(\n",
    "    plt.scatter(masked_cosine_sim[threshold_passers].ravel(),\n",
    "            sum_scores[threshold_passers].ravel(), alpha=0.1))\n",
    "plt.xlabel(\"Masked cosine similarity\")\n",
    "plt.ylabel(\"Sum score\")\n",
    "plt.legend(handles=handles, labels=[\"Not passing\", \"Passing\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbSutVUK0kZ-"
   },
   "source": [
    "From our retained hits, let us visualize the first few matches to the GATA motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "agaA8m0Q0kZ_",
    "outputId": "b8e14ee4-1fb6-4715-b6fe-33455223c633"
   },
   "outputs": [],
   "source": [
    "hit_locations = list(zip(*np.nonzero(threshold_passers)))\n",
    "num_to_viz = 5\n",
    "for (seq_idx, hit_pos) in hit_locations[:num_to_viz]:\n",
    "    print(\"cosine similarity:\", masked_cosine_sim[seq_idx,hit_pos],\n",
    "          \"sum scores:\", sum_scores[seq_idx, hit_pos])\n",
    "    viz_sequence.plot_weights(\n",
    "        imp_scores[seq_idx],\n",
    "        highlight={'red': [(hit_pos, hit_pos+len(trimmed_gata))]},\n",
    "        subticks_frequency=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1NHHOOaZ0kaA"
   },
   "source": [
    "Let us also visualize some regions that are very strong matches to the log-odds PWM, but which did not have a sufficiently high value for sum_scores and were thus not called as matches at our chosen sum_scores threshold (which was on the stringent sides). It turns out that these regions tend to lack the TAL (CAGATG) motif. Since task 0 is a 1 iff both TAL and GATA motifs are present in the sequence, it makes sense that GATA motifs in the absence of TAL would receive lower importance. This illustrates how looking at the importance scores at motif instances incorporates information about the surrounding context, such as the presence or absence of cofactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "HrV4gmd30kaB",
    "outputId": "670da074-28cd-4c4f-e843-a9cd1fb4a8a2"
   },
   "outputs": [],
   "source": [
    "#To compute scores from a simple log-odds pwm scan, we can use the code below\n",
    "# Note that because the simulation was generated using a position probability matrix (ppm), the scanning\n",
    "# with the log-odds pwm works better than the masked cosine similarity.\n",
    "#However, in-vivo TF binding is more complex than what can be characterized by a log-odds pwm - \n",
    "# see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3936734/\n",
    "logodds_pwm = modisco.util.get_logodds_pwm(ppm=trimmed_gata[\"sequence\"].fwd,\n",
    "                                           background=background, pseudocount=0.001)\n",
    "#For simplicity, we will only compute the scores for the forward version of the\n",
    "# motif since that was what was used in the simulation.\n",
    "fwd_logodds_pwm_scores = modisco.util.compute_pwm_scan(onehot_seq=onehot_seq,\n",
    "                                                weightmat=logodds_pwm)\n",
    "lower_imp_gata_hit_locations = list(zip(*np.nonzero((fwd_logodds_pwm_scores > 8)\n",
    "                                                    *(sum_scores < sum_score_thresh))))\n",
    "for (seq_idx, hit_pos) in lower_imp_gata_hit_locations[:num_to_viz]:\n",
    "    print(\"logodds pwm score:\", fwd_logodds_pwm_scores[seq_idx,hit_pos],\n",
    "          \"sum scores:\", sum_scores[seq_idx, hit_pos])\n",
    "    viz_sequence.plot_weights(\n",
    "        imp_scores[seq_idx],\n",
    "        highlight={'red': [(hit_pos, hit_pos+len(trimmed_gata))]},\n",
    "        subticks_frequency=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYkC2dIY0kaF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "(On Google Colab) With Hit Scoring TF MoDISco TAL GATA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
